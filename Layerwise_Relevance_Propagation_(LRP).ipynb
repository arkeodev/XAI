{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkeodev/XAI/blob/main/Layerwise_Relevance_Propagation_(LRP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXID--9mnuDh"
      },
      "source": [
        "## Layerwise Relevance Propagation (LRP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq-9jq0yn2Eq"
      },
      "source": [
        "LRP is a technique used to explain the predictions of complex models by tracing the prediction back through the layers of the network to the input features, thereby providing a visual map or a set of influential features that led to the decision.\n",
        "\n",
        "LRP has a theoretical foundation in Taylor decomposition, which helps explain the contributions of individual components (input features) to a function's (network's) output near a point (the input data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8J6_VqJYH46"
      },
      "source": [
        "<figure>\n",
        "    <img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp.png\" width=\"800\" height=\"300\" alt=\"LRP\">\n",
        "    <figcaption>LRP</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YY-5u0oYH46"
      },
      "source": [
        "### How LRP Works?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GHSQ7JxYH46"
      },
      "source": [
        "<figure>\n",
        "    <img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp-how-it-runs.png\" width=\"800\" height=\"300\" alt=\"How LRP Works?\">\n",
        "    <figcaption>How LRP Works?</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sxtBmyBYH47"
      },
      "source": [
        "Layer-wise Relevance Propagation (LRP) is a technique used in machine learning to understand and visualize the contribution of each input feature to the final prediction of a neural network. It's particularly useful for deep learning models, where the decision-making process can be quite opaque.\n",
        "\n",
        "**Step 1: Forward Pass**\n",
        "\n",
        "- Start with a trained neural network ready for making predictions.\n",
        "- Input your data (like an image) into the network.\n",
        "- Perform a forward pass through the network, where the input is processed layer by layer to arrive at a final prediction. This step is just like any other prediction process in neural networks.\n",
        "\n",
        "**Step 2: Prediction Output**\n",
        "\n",
        "- Capture the output of the network. This could be a class label in classification tasks or a value in regression tasks.\n",
        "- Select the output neuron(s) corresponding to the predicted class or value for relevance backpropagation.\n",
        "\n",
        "**Step 3: Select Relevance**\n",
        "\n",
        "- The relevance is initially set to the output of the network for the predicted class. For instance, if the network predicts \"dog\", the relevance is assigned to the output neuron that corresponds to \"dog\".\n",
        "- All other output neurons are set to have zero relevance since they did not contribute to the final prediction.\n",
        "\n",
        "**Step 4: Backward Pass with LRP**\n",
        "\n",
        "- Perform a backward pass starting from the selected output neuron.\n",
        "- At each layer, distribute the relevance from the layer above to the neurons in the current layer. This is done using LRP rules which define how to allocate relevance among neurons based on their contributions.\n",
        "- Continue this process layer by layer, moving from the output layer towards the input layer.\n",
        "\n",
        "**Step 5: LRP Decomposition Rules**\n",
        "\n",
        "- Apply specific LRP rules at each layer to decompose the relevance among the connected neurons. These rules are based on the contribution of each neuron to the activation of the neurons in the next layer.\n",
        "- Commonly used rules include the LRP-ε, LRP-γ, and LRP-0 rules, each with different properties and applications.\n",
        "\n",
        "**Step 6: Relevance Conservation**\n",
        "\n",
        "- Ensure that the total relevance is conserved at each layer. The sum of the relevance scores assigned to all neurons in one layer should equal the total relevance from the layer above.\n",
        "\n",
        "**Step 7: Generation of Heatmaps**\n",
        "\n",
        "- Once the relevance has been backpropagated to the input layer, use the computed relevance scores to generate a heatmap.\n",
        "- This heatmap visualizes the contribution of each input feature (like pixels in an image) to the network’s prediction.\n",
        "\n",
        "**Step 8: Interpretation and Validation**\n",
        "\n",
        "- Analyze the heatmap to interpret which features were most and least important for the model's prediction.\n",
        "- Validate the explanation by techniques like pixel-perturbation analysis, where input features deemed important by LRP are altered to see if they affect the model's output.\n",
        "\n",
        "**Step 9: Evaluation of Explanations**\n",
        "\n",
        "- Use quantitative methods to evaluate the quality of the explanations provided by LRP, such as comparing them with ground truth annotations when available, or assessing the impact of perturbations on the model’s prediction accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGnbRAd3-WAC"
      },
      "source": [
        "## Implementatation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction"
      ],
      "metadata": {
        "id": "rDDixlMLa4f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will apply LRP to a brain cancer classification task using medical MRI scans.\n",
        "\n",
        "MRI stands for Magnetic Resonance Imaging, and LRP helps us not only to identify if there's brain cancer in an image but also to understand why the model made its prediction. LRP is predominantly applied to neural networks but can be used with support vector machines as well.\n",
        "\n",
        "Our goal with LRP is to visually explain the decision of a model by showing which parts of an input, such as image pixels, contributed to a particular prediction."
      ],
      "metadata": {
        "id": "hQVyvSewYcCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "j9QGZamhYvRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding, it's important to check if a GPU is available for computation, as this will significantly speed up the training process."
      ],
      "metadata": {
        "id": "hqUJPiAKY9gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set GPU device\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7GUORfdZELF",
        "outputId": "6dd165ea-22f0-401f-9b36-1aed287e7a61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Downloading"
      ],
      "metadata": {
        "id": "wSZc3Oyda8a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will be using a dataset of brain MRI images. These images are organized into separate folders based on whether they show evidence of a tumor. The dataset contains both a training and a testing set, which I will load for our model."
      ],
      "metadata": {
        "id": "hotFo9O9ZUSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle -q"
      ],
      "metadata": {
        "id": "H-qdTCapbBgM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt the user for API username and key input\n",
        "kaggle_username = getpass('Enter your Kaggle username')\n",
        "kaggle_key = getpass('Enter your Kaggle API key')\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_username  # Sets the username as an environment variable\n",
        "os.environ['KAGGLE_KEY'] = kaggle_key            # Sets the key as an environment variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snqMvtHUcAaB",
        "outputId": "9b177984-b30a-4f8f-8e7b-899d43cd672b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Kaggle username··········\n",
            "Enter your Kaggle API key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdwe8bpAbKQJ",
        "outputId": "82ae0370-f3a2-4555-932c-7777b7ec71dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brain-tumor-classification-mri.zip to /content\n",
            " 98% 85.0M/86.8M [00:00<00:00, 181MB/s]\n",
            "100% 86.8M/86.8M [00:00<00:00, 149MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_ROOT = \"./data/brain_mri/Training\"\n",
        "TEST_ROOT = \"./data/brain_mri/Testing\""
      ],
      "metadata": {
        "id": "LIGr2G45cwF4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"./data/brain_mri\"  # Creates the directory and any necessary parent directories\n",
        "!unzip -q brain-tumor-classification-mri.zip -d \"./data/brain_mri\""
      ],
      "metadata": {
        "id": "qxVo3Fkwctin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Load data\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=TRAIN_ROOT)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=TRAIN_ROOT)"
      ],
      "metadata": {
        "id": "iDC7f75UZeGS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the Model"
      ],
      "metadata": {
        "id": "6pr6QEPAd6dB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct our neural network model based on the pre-trained VGG16 architecture, modifying the output layer to suit our four-class problem - identifying different types of brain tumors. This model adaptation allows us to leverage the powerful feature extraction capabilities of VGG16 while fine-tuning it for our specific task."
      ],
      "metadata": {
        "id": "V1Ts1001eBWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Building the model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "        # Replace output layer according to our problem\n",
        "        in_feats = self.vgg16.classifier[6].in_features\n",
        "        self.vgg16.classifier[6] = nn.Linear(in_feats, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vgg16(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YEl2HWeFGy",
        "outputId": "84f19de2-2ae6-4937-ec55-cbc1cc083f22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 102MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (vgg16): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=4096, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preprocessing"
      ],
      "metadata": {
        "id": "S3NlH2BPeMT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we apply the necessary transformations to our dataset images to fit the input requirements of the pre-trained VGG16 model. The images are resized and converted to tensors, ready for model consumption."
      ],
      "metadata": {
        "id": "CZ27BsUSeWaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Prepare data for pretrained model\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=TRAIN_ROOT,\n",
        "        transform=transforms.Compose([\n",
        "                      transforms.Resize((255,255)),\n",
        "                      transforms.ToTensor()\n",
        "        ])\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=TEST_ROOT,\n",
        "        transform=transforms.Compose([\n",
        "                      transforms.Resize((255,255)),\n",
        "                      transforms.ToTensor()\n",
        "        ])\n",
        ")"
      ],
      "metadata": {
        "id": "i6Deu13YeZaM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Data Loaders"
      ],
      "metadata": {
        "id": "JANJO3JDedpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loaders are an integral part of the training process, enabling efficient data manipulation and batching. Here, we define our data loaders for both the training and test sets with a batch size of 32."
      ],
      "metadata": {
        "id": "353mUlbeeha1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "NuxY0dG9egqI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Model"
      ],
      "metadata": {
        "id": "709OWfZFe0gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train our neural network model using the cross-entropy loss function and the Adam optimizer. The learning rate is set to a small value to fine-tune the pre-trained network. We will train the model for 10 epochs and print the loss for each batch to monitor the training progress."
      ],
      "metadata": {
        "id": "nyPne9kke3dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Train\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "epochs = 10\n",
        "\n",
        "# Iterate x epochs over the train data\n",
        "for epoch in range(epochs):\n",
        "    for i, batch in enumerate(train_loader, 0):\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        # Labels are automatically one-hot-encoded\n",
        "        loss = cross_entropy_loss(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsPu0y-Ge7r9",
        "outputId": "d27f3e63-beda-42f5-dadc-260d29aac4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1986, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspecting Predictions"
      ],
      "metadata": {
        "id": "7xbGaTN6fFeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, it's crucial to evaluate the model's performance. Here, we load a batch of test data and make predictions with the trained model. We calculate the batch accuracy by comparing the predicted labels with the ground truth and display the results in a dataframe for a clear comparison."
      ],
      "metadata": {
        "id": "ZkJfW9lBfJWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Inspect predictions for first batch\n",
        "inputs, labels = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.numpy()\n",
        "outputs = model(inputs).max(1).indices.detach().cpu().numpy()\n",
        "comparison = pd.DataFrame()\n",
        "print(\"Batch accuracy: \", (labels==outputs).sum()/len(labels))\n",
        "comparison[\"labels\"] = labels\n",
        "comparison[\"outputs\"] = outputs\n",
        "comparison"
      ],
      "metadata": {
        "id": "WdZudvljfNEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementing Layerwise Relevance Propagation (LRP)"
      ],
      "metadata": {
        "id": "-Oo9zxx4fRUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layerwise Relevance Propagation (LRP) aims to explain the decision-making process of neural networks. We start by defining functions to adapt our VGG16 model for LRP by transforming dense layers to convolutional ones and cloning layers while applying specific relevance rules. We then compute the relevances for each layer in reverse, starting from the output and working back to the input, essentially performing a backward pass of relevance scores.\n",
        "\n",
        "LRP assigns a relevance score to each neuron based on its contribution to the final decision. This score is backpropagated through the network's layers to the input layer. We treat different layers with specific rules - for lower layers, we focus on positive contributions, while for upper layers, we apply a more general rule without bias.\n",
        "\n",
        "This process helps us understand which parts of an input image the model finds most relevant for its prediction, giving us insight into its decision-making process."
      ],
      "metadata": {
        "id": "rDy6KdY8fU1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Layerwise relevance propagation for VGG16\n",
        "# For other CNN architectures this code might become more complex\n",
        "# Source: https://git.tu-berlin.de/gmontavon/lrp-tutorial\n",
        "# http://iphome.hhi.de/samek/pdf/MonXAI19.pdf\n",
        "\n",
        "def new_layer(layer, g):\n",
        "    \"\"\"Clone a layer and pass its parameters through the function g.\"\"\"\n",
        "    layer = copy.deepcopy(layer)\n",
        "    try: layer.weight = torch.nn.Parameter(g(layer.weight))\n",
        "    except AttributeError: pass\n",
        "    try: layer.bias = torch.nn.Parameter(g(layer.bias))\n",
        "    except AttributeError: pass\n",
        "    return layer\n",
        "\n",
        "def dense_to_conv(layers):\n",
        "    \"\"\" Converts a dense layer to a conv layer \"\"\"\n",
        "    newlayers = []\n",
        "    for i,layer in enumerate(layers):\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            newlayer = None\n",
        "            if i == 0:\n",
        "                m, n = 512, layer.weight.shape[0]\n",
        "                newlayer = nn.Conv2d(m,n,7)\n",
        "                newlayer.weight = nn.Parameter(layer.weight.reshape(n,m,7,7))\n",
        "            else:\n",
        "                m,n = layer.weight.shape[1],layer.weight.shape[0]\n",
        "                newlayer = nn.Conv2d(m,n,1)\n",
        "                newlayer.weight = nn.Parameter(layer.weight.reshape(n,m,1,1))\n",
        "            newlayer.bias = nn.Parameter(layer.bias)\n",
        "            newlayers += [newlayer]\n",
        "        else:\n",
        "            newlayers += [layer]\n",
        "    return newlayers\n",
        "\n",
        "def get_linear_layer_indices(model):\n",
        "    offset = len(model.vgg16._modules['features']) + 1\n",
        "    indices = []\n",
        "    for i, layer in enumerate(model.vgg16._modules['classifier']):\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            indices.append(i)\n",
        "    indices = [offset + val for val in indices]\n",
        "    return indices\n",
        "\n",
        "def apply_lrp_on_vgg16(model, image):\n",
        "    image = torch.unsqueeze(image, 0)\n",
        "    # >>> Step 1: Extract layers\n",
        "    layers = list(model.vgg16._modules['features']) \\\n",
        "                + [model.vgg16._modules['avgpool']] \\\n",
        "                + dense_to_conv(list(model.vgg16._modules['classifier']))\n",
        "    linear_layer_indices = get_linear_layer_indices(model)\n",
        "    # >>> Step 2: Propagate image through layers and store activations\n",
        "    n_layers = len(layers)\n",
        "    activations = [image] + [None] * n_layers # list of activations\n",
        "\n",
        "    for layer in range(n_layers):\n",
        "        if layer in linear_layer_indices:\n",
        "            if layer == 32:\n",
        "                activations[layer] = activations[layer].reshape((1, 512, 7, 7))\n",
        "        activation = layers[layer].forward(activations[layer])\n",
        "        if isinstance(layers[layer], torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
        "            activation = torch.flatten(activation, start_dim=1)\n",
        "        activations[layer+1] = activation\n",
        "\n",
        "    # >>> Step 3: Replace last layer with one-hot-encoding\n",
        "    output_activation = activations[-1].detach().cpu().numpy()\n",
        "    max_activation = output_activation.max()\n",
        "    one_hot_output = [val if val == max_activation else 0\n",
        "                        for val in output_activation[0]]\n",
        "\n",
        "   # activations[-1] = torch.FloatTensor([one_hot_output]).to(device)\n",
        "\n",
        "    # >>> Step 4: Backpropagate relevance scores\n",
        "    relevances = [None] * n_layers + [activations[-1]]\n",
        "    # Iterate over the layers in reverse order\n",
        "    for layer in range(0, n_layers)[::-1]:\n",
        "        current = layers[layer]\n",
        "        # Treat max pooling layers as avg pooling\n",
        "        if isinstance(current, torch.nn.MaxPool2d):\n",
        "            layers[layer] = torch.nn.AvgPool2d(2)\n",
        "            current = layers[layer]\n",
        "        if isinstance(current, torch.nn.Conv2d) or \\\n",
        "           isinstance(current, torch.nn.AvgPool2d) or\\\n",
        "           isinstance(current, torch.nn.Linear):\n",
        "            activations[layer] = activations[layer].data.requires_grad_(True)\n",
        "\n",
        "            # Apply variants of LRP depending on the depth\n",
        "            # see: https://link.springer.com/chapter/10.1007%2F978-3-030-28954-6_10\n",
        "            # Lower layers, LRP-gamma >> Favor positive contributions (activations)\n",
        "            if layer <= 16:       rho = lambda p: p + 0.25*p.clamp(min=0); incr = lambda z: z+1e-9\n",
        "            # Middle layers, LRP-epsilon >> Remove some noise / Only most salient factors survive\n",
        "            if 17 <= layer <= 30: rho = lambda p: p;                       incr = lambda z: z+1e-9+0.25*((z**2).mean()**.5).data\n",
        "            # Upper Layers, LRP-0 >> Basic rule\n",
        "            if layer >= 31:       rho = lambda p: p;                       incr = lambda z: z+1e-9\n",
        "\n",
        "            # Transform weights of layer and execute forward pass\n",
        "            z = incr(new_layer(layers[layer],rho).forward(activations[layer]))\n",
        "            # Element-wise division between relevance of the next layer and z\n",
        "            s = (relevances[layer+1]/z).data\n",
        "            # Calculate the gradient and multiply it by the activation\n",
        "            (z * s).sum().backward();\n",
        "            c = activations[layer].grad\n",
        "            # Assign new relevance values\n",
        "            relevances[layer] = (activations[layer]*c).data\n",
        "        else:\n",
        "            relevances[layer] = relevances[layer+1]\n",
        "\n",
        "    # >>> Potential Step 5: Apply different propagation rule for pixels\n",
        "    return relevances[0]"
      ],
      "metadata": {
        "id": "sl3j0fPDfYI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing Relevance Scores"
      ],
      "metadata": {
        "id": "CjdjbNAgfgZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the LRP implementation, we can now visualize the relevance scores for individual images. This cell demonstrates how to apply LRP to a specific test image and generate a heatmap of relevances, which helps us see which pixels were most influential in the model's prediction.\n",
        "\n",
        "We normalize the relevance scores to make them easier to visualize and use a color map to distinguish areas of high and low relevance. The resulting visualization can be compared with the original image to better understand the model's decision-making process. This kind of visualization is particularly useful in domains like medical imaging, where understanding the model's focus can be critical."
      ],
      "metadata": {
        "id": "gyoVPpL_fjW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Calculate relevances for first image in this test batch\n",
        "image_id = 2\n",
        "image_relevances = apply_lrp_on_vgg16(model, inputs[image_id])\n",
        "image_relevances = image_relevances.permute(0,2,3,1).detach().cpu().numpy()[0]\n",
        "image_relevances = np.interp(image_relevances, (image_relevances.min(),\n",
        "                                                image_relevances.max()),\n",
        "                                                (0, 1))\n",
        "# Show relevances\n",
        "pred_label = list(test_dataset.class_to_idx.keys())[\n",
        "             list(test_dataset.class_to_idx.values())\n",
        "            .index(labels[image_id])]\n",
        "if outputs[image_id] == labels[image_id]:\n",
        "    print(\"Groundtruth for this image: \", pred_label)\n",
        "\n",
        "    # Plot images next to each other\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image_relevances[:,:,0], cmap=\"seismic\")\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(inputs[image_id].permute(1,2,0).detach().cpu().numpy())\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"This image is not classified correctly.\")"
      ],
      "metadata": {
        "id": "NfB1hv1BfmmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUPmnD3g9w_l"
      },
      "source": [
        "## Explainable AI Demos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnp4iIYb9w_l"
      },
      "source": [
        "[Explainable AI Demos](https://lrpserver.hhi.fraunhofer.de/) is an educational or demonstration tool designed to make AI more accessible and understandable to users by visually and interactively showcasing how AI models arrive at their conclusions. There are four different types of demos:\n",
        "\n",
        "- Handwriting Classification: This demo seems to use LRP to explain how a neural network trained on the MNIST dataset predicts handwritten digits. It suggests that users can input their handwriting for the AI to classify and explain.\n",
        "- Image Classification: A more advanced LRP demo for image classification that uses a neural network implemented with Caffe, a deep learning framework. This demo likely illustrates how the AI model determines the content of images.\n",
        "- Text Classification: This is for classifying natural language documents. The neural network provides predictions on the document's semantic category and uses LRP to explain the classification process.\n",
        "- Visual Question Answering: This demo allows users to ask AI questions about an image and receive not only answers but also visual explanations that highlight relevant parts of the image involved in the AI's reasoning.\n",
        "<table>\n",
        "<tr>\n",
        "    <td style=\"padding: 10px;\"><img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp_text_recognition_and_classification.png\" alt=\"Text Recognition and Classification\" width=\"600\" /></td>\n",
        "    <td style=\"padding: 10px;\"><img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp_image_classification.png\" alt=\"Image Classification\" width=\"600\" /></td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td style=\"padding: 10px;\"><img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp_mnist_image_recognition.png\" alt=\"MNIST Image Recognition\" width=\"600\" /></td>\n",
        "    <td style=\"padding: 10px;\"><img src=\"https://raw.githubusercontent.com/arkeodev/XAI/main/images/lrp_question_and_answering.png\" alt=\"Question and Answering\" width=\"600\" /></td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEuibzQc-WAC"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlC4T3Gn-WAC"
      },
      "source": [
        "- Layer-Wise Relevance Propagation: An Overview (Paper): https://iphome.hhi.de/samek/pdf/MonXAI19.pdf\n",
        "- Layer-Wise Relevance Propogation: https://www.hhi.fraunhofer.de/en/departments/ai/technologies-and-solutions/layer-wise-relevance-propagation.html\n",
        "- Explainable AI Demos: https://lrpserver.hhi.fraunhofer.de/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}